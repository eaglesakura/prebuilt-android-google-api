// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: google/cloud/speech/v1beta1/cloud_speech.proto

package com.google.cloud.speech.v1beta1;

/**
 * <pre>
 * The `RecognitionConfig` message provides information to the recognizer
 * that specifies how to process the request.
 * </pre>
 *
 * Protobuf type {@code google.cloud.speech.v1beta1.RecognitionConfig}
 */
public  final class RecognitionConfig extends
    com.google.protobuf.GeneratedMessageLite<
        RecognitionConfig, RecognitionConfig.Builder> implements
    // @@protoc_insertion_point(message_implements:google.cloud.speech.v1beta1.RecognitionConfig)
    RecognitionConfigOrBuilder {
  private RecognitionConfig() {
    languageCode_ = "";
  }
  /**
   * <pre>
   * Audio encoding of the data sent in the audio message. All encodings support
   * only 1 channel (mono) audio. Only `FLAC` includes a header that describes
   * the bytes of audio that follow the header. The other encodings are raw
   * audio bytes with no header.
   * For best results, the audio source should be captured and transmitted using
   * a lossless encoding (`FLAC` or `LINEAR16`). Recognition accuracy may be
   * reduced if lossy codecs (such as AMR, AMR_WB and MULAW) are used to capture
   * or transmit the audio, particularly if background noise is present.
   * </pre>
   *
   * Protobuf enum {@code google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding}
   */
  public enum AudioEncoding
      implements com.google.protobuf.Internal.EnumLite {
    /**
     * <pre>
     * Not specified. Will return result [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT].
     * </pre>
     *
     * <code>ENCODING_UNSPECIFIED = 0;</code>
     */
    ENCODING_UNSPECIFIED(0),
    /**
     * <pre>
     * Uncompressed 16-bit signed little-endian samples (Linear PCM).
     * This is the only encoding that may be used by `AsyncRecognize`.
     * </pre>
     *
     * <code>LINEAR16 = 1;</code>
     */
    LINEAR16(1),
    /**
     * <pre>
     * This is the recommended encoding for `SyncRecognize` and
     * `StreamingRecognize` because it uses lossless compression; therefore
     * recognition accuracy is not compromised by a lossy codec.
     * The stream FLAC (Free Lossless Audio Codec) encoding is specified at:
     * http://flac.sourceforge.net/documentation.html.
     * 16-bit and 24-bit samples are supported.
     * Not all fields in STREAMINFO are supported.
     * </pre>
     *
     * <code>FLAC = 2;</code>
     */
    FLAC(2),
    /**
     * <pre>
     * 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
     * </pre>
     *
     * <code>MULAW = 3;</code>
     */
    MULAW(3),
    /**
     * <pre>
     * Adaptive Multi-Rate Narrowband codec. `sample_rate` must be 8000 Hz.
     * </pre>
     *
     * <code>AMR = 4;</code>
     */
    AMR(4),
    /**
     * <pre>
     * Adaptive Multi-Rate Wideband codec. `sample_rate` must be 16000 Hz.
     * </pre>
     *
     * <code>AMR_WB = 5;</code>
     */
    AMR_WB(5),
    UNRECOGNIZED(-1),
    ;

    /**
     * <pre>
     * Not specified. Will return result [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT].
     * </pre>
     *
     * <code>ENCODING_UNSPECIFIED = 0;</code>
     */
    public static final int ENCODING_UNSPECIFIED_VALUE = 0;
    /**
     * <pre>
     * Uncompressed 16-bit signed little-endian samples (Linear PCM).
     * This is the only encoding that may be used by `AsyncRecognize`.
     * </pre>
     *
     * <code>LINEAR16 = 1;</code>
     */
    public static final int LINEAR16_VALUE = 1;
    /**
     * <pre>
     * This is the recommended encoding for `SyncRecognize` and
     * `StreamingRecognize` because it uses lossless compression; therefore
     * recognition accuracy is not compromised by a lossy codec.
     * The stream FLAC (Free Lossless Audio Codec) encoding is specified at:
     * http://flac.sourceforge.net/documentation.html.
     * 16-bit and 24-bit samples are supported.
     * Not all fields in STREAMINFO are supported.
     * </pre>
     *
     * <code>FLAC = 2;</code>
     */
    public static final int FLAC_VALUE = 2;
    /**
     * <pre>
     * 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
     * </pre>
     *
     * <code>MULAW = 3;</code>
     */
    public static final int MULAW_VALUE = 3;
    /**
     * <pre>
     * Adaptive Multi-Rate Narrowband codec. `sample_rate` must be 8000 Hz.
     * </pre>
     *
     * <code>AMR = 4;</code>
     */
    public static final int AMR_VALUE = 4;
    /**
     * <pre>
     * Adaptive Multi-Rate Wideband codec. `sample_rate` must be 16000 Hz.
     * </pre>
     *
     * <code>AMR_WB = 5;</code>
     */
    public static final int AMR_WB_VALUE = 5;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static AudioEncoding valueOf(int value) {
      return forNumber(value);
    }

    public static AudioEncoding forNumber(int value) {
      switch (value) {
        case 0: return ENCODING_UNSPECIFIED;
        case 1: return LINEAR16;
        case 2: return FLAC;
        case 3: return MULAW;
        case 4: return AMR;
        case 5: return AMR_WB;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<AudioEncoding>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        AudioEncoding> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<AudioEncoding>() {
            public AudioEncoding findValueByNumber(int number) {
              return AudioEncoding.forNumber(number);
            }
          };

    private final int value;

    private AudioEncoding(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding)
  }

  public static final int ENCODING_FIELD_NUMBER = 1;
  private int encoding_;
  /**
   * <pre>
   * [Required] Encoding of audio data sent in all `RecognitionAudio` messages.
   * </pre>
   *
   * <code>optional .google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding encoding = 1;</code>
   */
  public int getEncodingValue() {
    return encoding_;
  }
  /**
   * <pre>
   * [Required] Encoding of audio data sent in all `RecognitionAudio` messages.
   * </pre>
   *
   * <code>optional .google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding encoding = 1;</code>
   */
  public com.google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding getEncoding() {
    com.google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding result = com.google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding.forNumber(encoding_);
    return result == null ? com.google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding.UNRECOGNIZED : result;
  }
  /**
   * <pre>
   * [Required] Encoding of audio data sent in all `RecognitionAudio` messages.
   * </pre>
   *
   * <code>optional .google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding encoding = 1;</code>
   */
  private void setEncodingValue(int value) {
      encoding_ = value;
  }
  /**
   * <pre>
   * [Required] Encoding of audio data sent in all `RecognitionAudio` messages.
   * </pre>
   *
   * <code>optional .google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding encoding = 1;</code>
   */
  private void setEncoding(com.google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding value) {
    if (value == null) {
      throw new NullPointerException();
    }
    
    encoding_ = value.getNumber();
  }
  /**
   * <pre>
   * [Required] Encoding of audio data sent in all `RecognitionAudio` messages.
   * </pre>
   *
   * <code>optional .google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding encoding = 1;</code>
   */
  private void clearEncoding() {
    
    encoding_ = 0;
  }

  public static final int SAMPLE_RATE_FIELD_NUMBER = 2;
  private int sampleRate_;
  /**
   * <pre>
   * [Required] Sample rate in Hertz of the audio data sent in all
   * `RecognitionAudio` messages. Valid values are: 8000-48000.
   * 16000 is optimal. For best results, set the sampling rate of the audio
   * source to 16000 Hz. If that's not possible, use the native sample rate of
   * the audio source (instead of re-sampling).
   * </pre>
   *
   * <code>optional int32 sample_rate = 2;</code>
   */
  public int getSampleRate() {
    return sampleRate_;
  }
  /**
   * <pre>
   * [Required] Sample rate in Hertz of the audio data sent in all
   * `RecognitionAudio` messages. Valid values are: 8000-48000.
   * 16000 is optimal. For best results, set the sampling rate of the audio
   * source to 16000 Hz. If that's not possible, use the native sample rate of
   * the audio source (instead of re-sampling).
   * </pre>
   *
   * <code>optional int32 sample_rate = 2;</code>
   */
  private void setSampleRate(int value) {
    
    sampleRate_ = value;
  }
  /**
   * <pre>
   * [Required] Sample rate in Hertz of the audio data sent in all
   * `RecognitionAudio` messages. Valid values are: 8000-48000.
   * 16000 is optimal. For best results, set the sampling rate of the audio
   * source to 16000 Hz. If that's not possible, use the native sample rate of
   * the audio source (instead of re-sampling).
   * </pre>
   *
   * <code>optional int32 sample_rate = 2;</code>
   */
  private void clearSampleRate() {
    
    sampleRate_ = 0;
  }

  public static final int LANGUAGE_CODE_FIELD_NUMBER = 3;
  private java.lang.String languageCode_;
  /**
   * <pre>
   * [Optional] The language of the supplied audio as a BCP-47 language tag.
   * Example: "en-GB"  https://www.rfc-editor.org/rfc/bcp/bcp47.txt
   * If omitted, defaults to "en-US". See
   * [Language Support](https://cloud.google.com/speech/docs/best-practices#language_support)
   * for a list of the currently supported language codes.
   * </pre>
   *
   * <code>optional string language_code = 3;</code>
   */
  public java.lang.String getLanguageCode() {
    return languageCode_;
  }
  /**
   * <pre>
   * [Optional] The language of the supplied audio as a BCP-47 language tag.
   * Example: "en-GB"  https://www.rfc-editor.org/rfc/bcp/bcp47.txt
   * If omitted, defaults to "en-US". See
   * [Language Support](https://cloud.google.com/speech/docs/best-practices#language_support)
   * for a list of the currently supported language codes.
   * </pre>
   *
   * <code>optional string language_code = 3;</code>
   */
  public com.google.protobuf.ByteString
      getLanguageCodeBytes() {
    return com.google.protobuf.ByteString.copyFromUtf8(languageCode_);
  }
  /**
   * <pre>
   * [Optional] The language of the supplied audio as a BCP-47 language tag.
   * Example: "en-GB"  https://www.rfc-editor.org/rfc/bcp/bcp47.txt
   * If omitted, defaults to "en-US". See
   * [Language Support](https://cloud.google.com/speech/docs/best-practices#language_support)
   * for a list of the currently supported language codes.
   * </pre>
   *
   * <code>optional string language_code = 3;</code>
   */
  private void setLanguageCode(
      java.lang.String value) {
    if (value == null) {
    throw new NullPointerException();
  }
  
    languageCode_ = value;
  }
  /**
   * <pre>
   * [Optional] The language of the supplied audio as a BCP-47 language tag.
   * Example: "en-GB"  https://www.rfc-editor.org/rfc/bcp/bcp47.txt
   * If omitted, defaults to "en-US". See
   * [Language Support](https://cloud.google.com/speech/docs/best-practices#language_support)
   * for a list of the currently supported language codes.
   * </pre>
   *
   * <code>optional string language_code = 3;</code>
   */
  private void clearLanguageCode() {
    
    languageCode_ = getDefaultInstance().getLanguageCode();
  }
  /**
   * <pre>
   * [Optional] The language of the supplied audio as a BCP-47 language tag.
   * Example: "en-GB"  https://www.rfc-editor.org/rfc/bcp/bcp47.txt
   * If omitted, defaults to "en-US". See
   * [Language Support](https://cloud.google.com/speech/docs/best-practices#language_support)
   * for a list of the currently supported language codes.
   * </pre>
   *
   * <code>optional string language_code = 3;</code>
   */
  private void setLanguageCodeBytes(
      com.google.protobuf.ByteString value) {
    if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
    
    languageCode_ = value.toStringUtf8();
  }

  public static final int MAX_ALTERNATIVES_FIELD_NUMBER = 4;
  private int maxAlternatives_;
  /**
   * <pre>
   * [Optional] Maximum number of recognition hypotheses to be returned.
   * Specifically, the maximum number of `SpeechRecognitionAlternative` messages
   * within each `SpeechRecognitionResult`.
   * The server may return fewer than `max_alternatives`.
   * Valid values are `0`-`30`. A value of `0` or `1` will return a maximum of
   * `1`. If omitted, defaults to `1`.
   * </pre>
   *
   * <code>optional int32 max_alternatives = 4;</code>
   */
  public int getMaxAlternatives() {
    return maxAlternatives_;
  }
  /**
   * <pre>
   * [Optional] Maximum number of recognition hypotheses to be returned.
   * Specifically, the maximum number of `SpeechRecognitionAlternative` messages
   * within each `SpeechRecognitionResult`.
   * The server may return fewer than `max_alternatives`.
   * Valid values are `0`-`30`. A value of `0` or `1` will return a maximum of
   * `1`. If omitted, defaults to `1`.
   * </pre>
   *
   * <code>optional int32 max_alternatives = 4;</code>
   */
  private void setMaxAlternatives(int value) {
    
    maxAlternatives_ = value;
  }
  /**
   * <pre>
   * [Optional] Maximum number of recognition hypotheses to be returned.
   * Specifically, the maximum number of `SpeechRecognitionAlternative` messages
   * within each `SpeechRecognitionResult`.
   * The server may return fewer than `max_alternatives`.
   * Valid values are `0`-`30`. A value of `0` or `1` will return a maximum of
   * `1`. If omitted, defaults to `1`.
   * </pre>
   *
   * <code>optional int32 max_alternatives = 4;</code>
   */
  private void clearMaxAlternatives() {
    
    maxAlternatives_ = 0;
  }

  public static final int PROFANITY_FILTER_FIELD_NUMBER = 5;
  private boolean profanityFilter_;
  /**
   * <pre>
   * [Optional] If set to `true`, the server will attempt to filter out
   * profanities, replacing all but the initial character in each filtered word
   * with asterisks, e.g. "f***". If set to `false` or omitted, profanities
   * won't be filtered out.
   * </pre>
   *
   * <code>optional bool profanity_filter = 5;</code>
   */
  public boolean getProfanityFilter() {
    return profanityFilter_;
  }
  /**
   * <pre>
   * [Optional] If set to `true`, the server will attempt to filter out
   * profanities, replacing all but the initial character in each filtered word
   * with asterisks, e.g. "f***". If set to `false` or omitted, profanities
   * won't be filtered out.
   * </pre>
   *
   * <code>optional bool profanity_filter = 5;</code>
   */
  private void setProfanityFilter(boolean value) {
    
    profanityFilter_ = value;
  }
  /**
   * <pre>
   * [Optional] If set to `true`, the server will attempt to filter out
   * profanities, replacing all but the initial character in each filtered word
   * with asterisks, e.g. "f***". If set to `false` or omitted, profanities
   * won't be filtered out.
   * </pre>
   *
   * <code>optional bool profanity_filter = 5;</code>
   */
  private void clearProfanityFilter() {
    
    profanityFilter_ = false;
  }

  public static final int SPEECH_CONTEXT_FIELD_NUMBER = 6;
  private com.google.cloud.speech.v1beta1.SpeechContext speechContext_;
  /**
   * <pre>
   * [Optional] A means to provide context to assist the speech recognition.
   * </pre>
   *
   * <code>optional .google.cloud.speech.v1beta1.SpeechContext speech_context = 6;</code>
   */
  public boolean hasSpeechContext() {
    return speechContext_ != null;
  }
  /**
   * <pre>
   * [Optional] A means to provide context to assist the speech recognition.
   * </pre>
   *
   * <code>optional .google.cloud.speech.v1beta1.SpeechContext speech_context = 6;</code>
   */
  public com.google.cloud.speech.v1beta1.SpeechContext getSpeechContext() {
    return speechContext_ == null ? com.google.cloud.speech.v1beta1.SpeechContext.getDefaultInstance() : speechContext_;
  }
  /**
   * <pre>
   * [Optional] A means to provide context to assist the speech recognition.
   * </pre>
   *
   * <code>optional .google.cloud.speech.v1beta1.SpeechContext speech_context = 6;</code>
   */
  private void setSpeechContext(com.google.cloud.speech.v1beta1.SpeechContext value) {
    if (value == null) {
      throw new NullPointerException();
    }
    speechContext_ = value;
    
    }
  /**
   * <pre>
   * [Optional] A means to provide context to assist the speech recognition.
   * </pre>
   *
   * <code>optional .google.cloud.speech.v1beta1.SpeechContext speech_context = 6;</code>
   */
  private void setSpeechContext(
      com.google.cloud.speech.v1beta1.SpeechContext.Builder builderForValue) {
    speechContext_ = builderForValue.build();
    
  }
  /**
   * <pre>
   * [Optional] A means to provide context to assist the speech recognition.
   * </pre>
   *
   * <code>optional .google.cloud.speech.v1beta1.SpeechContext speech_context = 6;</code>
   */
  private void mergeSpeechContext(com.google.cloud.speech.v1beta1.SpeechContext value) {
    if (speechContext_ != null &&
        speechContext_ != com.google.cloud.speech.v1beta1.SpeechContext.getDefaultInstance()) {
      speechContext_ =
        com.google.cloud.speech.v1beta1.SpeechContext.newBuilder(speechContext_).mergeFrom(value).buildPartial();
    } else {
      speechContext_ = value;
    }
    
  }
  /**
   * <pre>
   * [Optional] A means to provide context to assist the speech recognition.
   * </pre>
   *
   * <code>optional .google.cloud.speech.v1beta1.SpeechContext speech_context = 6;</code>
   */
  private void clearSpeechContext() {  speechContext_ = null;
    
  }

  public void writeTo(com.google.protobuf.CodedOutputStream output)
                      throws java.io.IOException {
    if (encoding_ != com.google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding.ENCODING_UNSPECIFIED.getNumber()) {
      output.writeEnum(1, encoding_);
    }
    if (sampleRate_ != 0) {
      output.writeInt32(2, sampleRate_);
    }
    if (!languageCode_.isEmpty()) {
      output.writeString(3, getLanguageCode());
    }
    if (maxAlternatives_ != 0) {
      output.writeInt32(4, maxAlternatives_);
    }
    if (profanityFilter_ != false) {
      output.writeBool(5, profanityFilter_);
    }
    if (speechContext_ != null) {
      output.writeMessage(6, getSpeechContext());
    }
  }

  public int getSerializedSize() {
    int size = memoizedSerializedSize;
    if (size != -1) return size;

    size = 0;
    if (encoding_ != com.google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding.ENCODING_UNSPECIFIED.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(1, encoding_);
    }
    if (sampleRate_ != 0) {
      size += com.google.protobuf.CodedOutputStream
        .computeInt32Size(2, sampleRate_);
    }
    if (!languageCode_.isEmpty()) {
      size += com.google.protobuf.CodedOutputStream
        .computeStringSize(3, getLanguageCode());
    }
    if (maxAlternatives_ != 0) {
      size += com.google.protobuf.CodedOutputStream
        .computeInt32Size(4, maxAlternatives_);
    }
    if (profanityFilter_ != false) {
      size += com.google.protobuf.CodedOutputStream
        .computeBoolSize(5, profanityFilter_);
    }
    if (speechContext_ != null) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(6, getSpeechContext());
    }
    memoizedSerializedSize = size;
    return size;
  }

  public static com.google.cloud.speech.v1beta1.RecognitionConfig parseFrom(
      com.google.protobuf.ByteString data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, data);
  }
  public static com.google.cloud.speech.v1beta1.RecognitionConfig parseFrom(
      com.google.protobuf.ByteString data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, data, extensionRegistry);
  }
  public static com.google.cloud.speech.v1beta1.RecognitionConfig parseFrom(byte[] data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, data);
  }
  public static com.google.cloud.speech.v1beta1.RecognitionConfig parseFrom(
      byte[] data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, data, extensionRegistry);
  }
  public static com.google.cloud.speech.v1beta1.RecognitionConfig parseFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, input);
  }
  public static com.google.cloud.speech.v1beta1.RecognitionConfig parseFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, input, extensionRegistry);
  }
  public static com.google.cloud.speech.v1beta1.RecognitionConfig parseDelimitedFrom(java.io.InputStream input)
      throws java.io.IOException {
    return parseDelimitedFrom(DEFAULT_INSTANCE, input);
  }
  public static com.google.cloud.speech.v1beta1.RecognitionConfig parseDelimitedFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return parseDelimitedFrom(DEFAULT_INSTANCE, input, extensionRegistry);
  }
  public static com.google.cloud.speech.v1beta1.RecognitionConfig parseFrom(
      com.google.protobuf.CodedInputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, input);
  }
  public static com.google.cloud.speech.v1beta1.RecognitionConfig parseFrom(
      com.google.protobuf.CodedInputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, input, extensionRegistry);
  }

  public static Builder newBuilder() {
    return DEFAULT_INSTANCE.toBuilder();
  }
  public static Builder newBuilder(com.google.cloud.speech.v1beta1.RecognitionConfig prototype) {
    return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
  }

  /**
   * <pre>
   * The `RecognitionConfig` message provides information to the recognizer
   * that specifies how to process the request.
   * </pre>
   *
   * Protobuf type {@code google.cloud.speech.v1beta1.RecognitionConfig}
   */
  public static final class Builder extends
      com.google.protobuf.GeneratedMessageLite.Builder<
        com.google.cloud.speech.v1beta1.RecognitionConfig, Builder> implements
      // @@protoc_insertion_point(builder_implements:google.cloud.speech.v1beta1.RecognitionConfig)
      com.google.cloud.speech.v1beta1.RecognitionConfigOrBuilder {
    // Construct using com.google.cloud.speech.v1beta1.RecognitionConfig.newBuilder()
    private Builder() {
      super(DEFAULT_INSTANCE);
    }


    /**
     * <pre>
     * [Required] Encoding of audio data sent in all `RecognitionAudio` messages.
     * </pre>
     *
     * <code>optional .google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding encoding = 1;</code>
     */
    public int getEncodingValue() {
      return instance.getEncodingValue();
    }
    /**
     * <pre>
     * [Required] Encoding of audio data sent in all `RecognitionAudio` messages.
     * </pre>
     *
     * <code>optional .google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding encoding = 1;</code>
     */
    public Builder setEncodingValue(int value) {
      copyOnWrite();
      instance.setEncodingValue(value);
      return this;
    }
    /**
     * <pre>
     * [Required] Encoding of audio data sent in all `RecognitionAudio` messages.
     * </pre>
     *
     * <code>optional .google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding encoding = 1;</code>
     */
    public com.google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding getEncoding() {
      return instance.getEncoding();
    }
    /**
     * <pre>
     * [Required] Encoding of audio data sent in all `RecognitionAudio` messages.
     * </pre>
     *
     * <code>optional .google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding encoding = 1;</code>
     */
    public Builder setEncoding(com.google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding value) {
      copyOnWrite();
      instance.setEncoding(value);
      return this;
    }
    /**
     * <pre>
     * [Required] Encoding of audio data sent in all `RecognitionAudio` messages.
     * </pre>
     *
     * <code>optional .google.cloud.speech.v1beta1.RecognitionConfig.AudioEncoding encoding = 1;</code>
     */
    public Builder clearEncoding() {
      copyOnWrite();
      instance.clearEncoding();
      return this;
    }

    /**
     * <pre>
     * [Required] Sample rate in Hertz of the audio data sent in all
     * `RecognitionAudio` messages. Valid values are: 8000-48000.
     * 16000 is optimal. For best results, set the sampling rate of the audio
     * source to 16000 Hz. If that's not possible, use the native sample rate of
     * the audio source (instead of re-sampling).
     * </pre>
     *
     * <code>optional int32 sample_rate = 2;</code>
     */
    public int getSampleRate() {
      return instance.getSampleRate();
    }
    /**
     * <pre>
     * [Required] Sample rate in Hertz of the audio data sent in all
     * `RecognitionAudio` messages. Valid values are: 8000-48000.
     * 16000 is optimal. For best results, set the sampling rate of the audio
     * source to 16000 Hz. If that's not possible, use the native sample rate of
     * the audio source (instead of re-sampling).
     * </pre>
     *
     * <code>optional int32 sample_rate = 2;</code>
     */
    public Builder setSampleRate(int value) {
      copyOnWrite();
      instance.setSampleRate(value);
      return this;
    }
    /**
     * <pre>
     * [Required] Sample rate in Hertz of the audio data sent in all
     * `RecognitionAudio` messages. Valid values are: 8000-48000.
     * 16000 is optimal. For best results, set the sampling rate of the audio
     * source to 16000 Hz. If that's not possible, use the native sample rate of
     * the audio source (instead of re-sampling).
     * </pre>
     *
     * <code>optional int32 sample_rate = 2;</code>
     */
    public Builder clearSampleRate() {
      copyOnWrite();
      instance.clearSampleRate();
      return this;
    }

    /**
     * <pre>
     * [Optional] The language of the supplied audio as a BCP-47 language tag.
     * Example: "en-GB"  https://www.rfc-editor.org/rfc/bcp/bcp47.txt
     * If omitted, defaults to "en-US". See
     * [Language Support](https://cloud.google.com/speech/docs/best-practices#language_support)
     * for a list of the currently supported language codes.
     * </pre>
     *
     * <code>optional string language_code = 3;</code>
     */
    public java.lang.String getLanguageCode() {
      return instance.getLanguageCode();
    }
    /**
     * <pre>
     * [Optional] The language of the supplied audio as a BCP-47 language tag.
     * Example: "en-GB"  https://www.rfc-editor.org/rfc/bcp/bcp47.txt
     * If omitted, defaults to "en-US". See
     * [Language Support](https://cloud.google.com/speech/docs/best-practices#language_support)
     * for a list of the currently supported language codes.
     * </pre>
     *
     * <code>optional string language_code = 3;</code>
     */
    public com.google.protobuf.ByteString
        getLanguageCodeBytes() {
      return instance.getLanguageCodeBytes();
    }
    /**
     * <pre>
     * [Optional] The language of the supplied audio as a BCP-47 language tag.
     * Example: "en-GB"  https://www.rfc-editor.org/rfc/bcp/bcp47.txt
     * If omitted, defaults to "en-US". See
     * [Language Support](https://cloud.google.com/speech/docs/best-practices#language_support)
     * for a list of the currently supported language codes.
     * </pre>
     *
     * <code>optional string language_code = 3;</code>
     */
    public Builder setLanguageCode(
        java.lang.String value) {
      copyOnWrite();
      instance.setLanguageCode(value);
      return this;
    }
    /**
     * <pre>
     * [Optional] The language of the supplied audio as a BCP-47 language tag.
     * Example: "en-GB"  https://www.rfc-editor.org/rfc/bcp/bcp47.txt
     * If omitted, defaults to "en-US". See
     * [Language Support](https://cloud.google.com/speech/docs/best-practices#language_support)
     * for a list of the currently supported language codes.
     * </pre>
     *
     * <code>optional string language_code = 3;</code>
     */
    public Builder clearLanguageCode() {
      copyOnWrite();
      instance.clearLanguageCode();
      return this;
    }
    /**
     * <pre>
     * [Optional] The language of the supplied audio as a BCP-47 language tag.
     * Example: "en-GB"  https://www.rfc-editor.org/rfc/bcp/bcp47.txt
     * If omitted, defaults to "en-US". See
     * [Language Support](https://cloud.google.com/speech/docs/best-practices#language_support)
     * for a list of the currently supported language codes.
     * </pre>
     *
     * <code>optional string language_code = 3;</code>
     */
    public Builder setLanguageCodeBytes(
        com.google.protobuf.ByteString value) {
      copyOnWrite();
      instance.setLanguageCodeBytes(value);
      return this;
    }

    /**
     * <pre>
     * [Optional] Maximum number of recognition hypotheses to be returned.
     * Specifically, the maximum number of `SpeechRecognitionAlternative` messages
     * within each `SpeechRecognitionResult`.
     * The server may return fewer than `max_alternatives`.
     * Valid values are `0`-`30`. A value of `0` or `1` will return a maximum of
     * `1`. If omitted, defaults to `1`.
     * </pre>
     *
     * <code>optional int32 max_alternatives = 4;</code>
     */
    public int getMaxAlternatives() {
      return instance.getMaxAlternatives();
    }
    /**
     * <pre>
     * [Optional] Maximum number of recognition hypotheses to be returned.
     * Specifically, the maximum number of `SpeechRecognitionAlternative` messages
     * within each `SpeechRecognitionResult`.
     * The server may return fewer than `max_alternatives`.
     * Valid values are `0`-`30`. A value of `0` or `1` will return a maximum of
     * `1`. If omitted, defaults to `1`.
     * </pre>
     *
     * <code>optional int32 max_alternatives = 4;</code>
     */
    public Builder setMaxAlternatives(int value) {
      copyOnWrite();
      instance.setMaxAlternatives(value);
      return this;
    }
    /**
     * <pre>
     * [Optional] Maximum number of recognition hypotheses to be returned.
     * Specifically, the maximum number of `SpeechRecognitionAlternative` messages
     * within each `SpeechRecognitionResult`.
     * The server may return fewer than `max_alternatives`.
     * Valid values are `0`-`30`. A value of `0` or `1` will return a maximum of
     * `1`. If omitted, defaults to `1`.
     * </pre>
     *
     * <code>optional int32 max_alternatives = 4;</code>
     */
    public Builder clearMaxAlternatives() {
      copyOnWrite();
      instance.clearMaxAlternatives();
      return this;
    }

    /**
     * <pre>
     * [Optional] If set to `true`, the server will attempt to filter out
     * profanities, replacing all but the initial character in each filtered word
     * with asterisks, e.g. "f***". If set to `false` or omitted, profanities
     * won't be filtered out.
     * </pre>
     *
     * <code>optional bool profanity_filter = 5;</code>
     */
    public boolean getProfanityFilter() {
      return instance.getProfanityFilter();
    }
    /**
     * <pre>
     * [Optional] If set to `true`, the server will attempt to filter out
     * profanities, replacing all but the initial character in each filtered word
     * with asterisks, e.g. "f***". If set to `false` or omitted, profanities
     * won't be filtered out.
     * </pre>
     *
     * <code>optional bool profanity_filter = 5;</code>
     */
    public Builder setProfanityFilter(boolean value) {
      copyOnWrite();
      instance.setProfanityFilter(value);
      return this;
    }
    /**
     * <pre>
     * [Optional] If set to `true`, the server will attempt to filter out
     * profanities, replacing all but the initial character in each filtered word
     * with asterisks, e.g. "f***". If set to `false` or omitted, profanities
     * won't be filtered out.
     * </pre>
     *
     * <code>optional bool profanity_filter = 5;</code>
     */
    public Builder clearProfanityFilter() {
      copyOnWrite();
      instance.clearProfanityFilter();
      return this;
    }

    /**
     * <pre>
     * [Optional] A means to provide context to assist the speech recognition.
     * </pre>
     *
     * <code>optional .google.cloud.speech.v1beta1.SpeechContext speech_context = 6;</code>
     */
    public boolean hasSpeechContext() {
      return instance.hasSpeechContext();
    }
    /**
     * <pre>
     * [Optional] A means to provide context to assist the speech recognition.
     * </pre>
     *
     * <code>optional .google.cloud.speech.v1beta1.SpeechContext speech_context = 6;</code>
     */
    public com.google.cloud.speech.v1beta1.SpeechContext getSpeechContext() {
      return instance.getSpeechContext();
    }
    /**
     * <pre>
     * [Optional] A means to provide context to assist the speech recognition.
     * </pre>
     *
     * <code>optional .google.cloud.speech.v1beta1.SpeechContext speech_context = 6;</code>
     */
    public Builder setSpeechContext(com.google.cloud.speech.v1beta1.SpeechContext value) {
      copyOnWrite();
      instance.setSpeechContext(value);
      return this;
      }
    /**
     * <pre>
     * [Optional] A means to provide context to assist the speech recognition.
     * </pre>
     *
     * <code>optional .google.cloud.speech.v1beta1.SpeechContext speech_context = 6;</code>
     */
    public Builder setSpeechContext(
        com.google.cloud.speech.v1beta1.SpeechContext.Builder builderForValue) {
      copyOnWrite();
      instance.setSpeechContext(builderForValue);
      return this;
    }
    /**
     * <pre>
     * [Optional] A means to provide context to assist the speech recognition.
     * </pre>
     *
     * <code>optional .google.cloud.speech.v1beta1.SpeechContext speech_context = 6;</code>
     */
    public Builder mergeSpeechContext(com.google.cloud.speech.v1beta1.SpeechContext value) {
      copyOnWrite();
      instance.mergeSpeechContext(value);
      return this;
    }
    /**
     * <pre>
     * [Optional] A means to provide context to assist the speech recognition.
     * </pre>
     *
     * <code>optional .google.cloud.speech.v1beta1.SpeechContext speech_context = 6;</code>
     */
    public Builder clearSpeechContext() {  copyOnWrite();
      instance.clearSpeechContext();
      return this;
    }

    // @@protoc_insertion_point(builder_scope:google.cloud.speech.v1beta1.RecognitionConfig)
  }
  protected final Object dynamicMethod(
      com.google.protobuf.GeneratedMessageLite.MethodToInvoke method,
      Object arg0, Object arg1) {
    switch (method) {
      case NEW_MUTABLE_INSTANCE: {
        return new com.google.cloud.speech.v1beta1.RecognitionConfig();
      }
      case IS_INITIALIZED: {
        return DEFAULT_INSTANCE;
      }
      case MAKE_IMMUTABLE: {
        return null;
      }
      case NEW_BUILDER: {
        return new Builder();
      }
      case VISIT: {
        Visitor visitor = (Visitor) arg0;
        com.google.cloud.speech.v1beta1.RecognitionConfig other = (com.google.cloud.speech.v1beta1.RecognitionConfig) arg1;
        encoding_ = visitor.visitInt(encoding_ != 0, encoding_,    other.encoding_ != 0, other.encoding_);
        sampleRate_ = visitor.visitInt(sampleRate_ != 0, sampleRate_,
            other.sampleRate_ != 0, other.sampleRate_);
        languageCode_ = visitor.visitString(!languageCode_.isEmpty(), languageCode_,
            !other.languageCode_.isEmpty(), other.languageCode_);
        maxAlternatives_ = visitor.visitInt(maxAlternatives_ != 0, maxAlternatives_,
            other.maxAlternatives_ != 0, other.maxAlternatives_);
        profanityFilter_ = visitor.visitBoolean(profanityFilter_ != false, profanityFilter_,
            other.profanityFilter_ != false, other.profanityFilter_);
        speechContext_ = visitor.visitMessage(speechContext_, other.speechContext_);
        if (visitor == com.google.protobuf.GeneratedMessageLite.MergeFromVisitor
            .INSTANCE) {
        }
        return this;
      }
      case MERGE_FROM_STREAM: {
        com.google.protobuf.CodedInputStream input =
            (com.google.protobuf.CodedInputStream) arg0;
        com.google.protobuf.ExtensionRegistryLite extensionRegistry =
            (com.google.protobuf.ExtensionRegistryLite) arg1;
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!input.skipField(tag)) {
                  done = true;
                }
                break;
              }
              case 8: {
                int rawValue = input.readEnum();

                encoding_ = rawValue;
                break;
              }
              case 16: {

                sampleRate_ = input.readInt32();
                break;
              }
              case 26: {
                String s = input.readStringRequireUtf8();

                languageCode_ = s;
                break;
              }
              case 32: {

                maxAlternatives_ = input.readInt32();
                break;
              }
              case 40: {

                profanityFilter_ = input.readBool();
                break;
              }
              case 50: {
                com.google.cloud.speech.v1beta1.SpeechContext.Builder subBuilder = null;
                if (speechContext_ != null) {
                  subBuilder = speechContext_.toBuilder();
                }
                speechContext_ = input.readMessage(com.google.cloud.speech.v1beta1.SpeechContext.parser(), extensionRegistry);
                if (subBuilder != null) {
                  subBuilder.mergeFrom(speechContext_);
                  speechContext_ = subBuilder.buildPartial();
                }

                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw new RuntimeException(e.setUnfinishedMessage(this));
        } catch (java.io.IOException e) {
          throw new RuntimeException(
              new com.google.protobuf.InvalidProtocolBufferException(
                  e.getMessage()).setUnfinishedMessage(this));
        } finally {
        }
      }
      case GET_DEFAULT_INSTANCE: {
        return DEFAULT_INSTANCE;
      }
      case GET_PARSER: {
        if (PARSER == null) {    synchronized (com.google.cloud.speech.v1beta1.RecognitionConfig.class) {
            if (PARSER == null) {
              PARSER = new DefaultInstanceBasedParser(DEFAULT_INSTANCE);
            }
          }
        }
        return PARSER;
      }
    }
    throw new UnsupportedOperationException();
  }


  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.RecognitionConfig)
  private static final com.google.cloud.speech.v1beta1.RecognitionConfig DEFAULT_INSTANCE;
  static {
    DEFAULT_INSTANCE = new RecognitionConfig();
    DEFAULT_INSTANCE.makeImmutable();
  }

  public static com.google.cloud.speech.v1beta1.RecognitionConfig getDefaultInstance() {
    return DEFAULT_INSTANCE;
  }

  private static volatile com.google.protobuf.Parser<RecognitionConfig> PARSER;

  public static com.google.protobuf.Parser<RecognitionConfig> parser() {
    return DEFAULT_INSTANCE.getParserForType();
  }
}

